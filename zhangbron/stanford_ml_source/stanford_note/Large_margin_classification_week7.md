## Support Vector Machine

凸优化问题，存在全局最优

### Large Margin Classification

逻辑回归与svm的一个区别是：

逻辑回归假设函数$h(\theta)$的输出是一个概率值，而svm的假设函数输出的是0或者1的离散值。

<img src="image/alternative_l_r.png">

<img src="image/svm1.png">

<img src="image/svm3.png">

<img src="image/svm4.png">



### Kernels

<img src="image/non_linear.png">



<img src="image/kernel1.png">



<img src="image/fe.png">



<img src="image/landmarks.png">

<img src="image/kernel2.png">

<img src="image/kernel3.png">



<img src="image/svm5.png">



<img src="image/svm6.png">

<img src="image/svm7.png">

<img src="image/svm8.png">



### multi-class classification

- one vs all like linear regression

<img src="image/svm9.png">

<img src="image/svm10.png">